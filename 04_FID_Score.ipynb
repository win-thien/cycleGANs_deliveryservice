{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBFFsYZQJk0R"
      },
      "source": [
        "### Thien Win\n",
        "BrainStation Data Science Capstone <br>\n",
        "April 2022 <br>\n",
        "\n",
        "</br>\n",
        "\n",
        "##### Notebook Table of Contents: <br>\n",
        "[1] Data Scraping and Wrangling <br>\n",
        "[2] CycleGAN Training <br>\n",
        "[3] Model Evaluation <br>\n",
        "<b>[4] FID Score </b><br>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7_peDgSJnPZ"
      },
      "source": [
        "### [4] FID Score\n",
        "\n",
        "##### Recommended Computing: Google Colab Pro(+) / TPU\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm2GAvzZKi3X"
      },
      "source": [
        "#### Introduction\n",
        "\n",
        "As demonstrated in the last notebook `[3] Model Evaluation`, when evaluating image quality from a subjective point of view, there can be discrepancies from image to image and from generator to generator.  \n",
        "\n",
        "GAN models and their associated generated images are notoriously difficult to evaluate. Model evaluation is important as it informs the builder of the correct model, when to stop training or how different changes impact model performance. Out of the several studied areas, I have decided to use the Frèchet Inception Distance (FID) score as a performance metric.\n",
        "\n",
        "The FID score is a performance metric that calculates the distance between the feature vectors of real images (real Studio Ghibli images in this case) and the feature vectors of the associated generated “fake” images. The FID Score uses the Inception v3 model to this effort. In practice, a lower FID score has been shown to correlate with higher quality generated images with a perfect score of 0.0 indicating that the real and generated images are identical. Unfortunately, there is no baseline metric to determine if a FID score is good (ie a FID score < x is good). I am using it in this case to only compare different levels of training.\n",
        "\n",
        "In this notebook, I will be defining the FID scoring method and evaluating the generated images from the previous notebook and associated generator to quantitatively select the best performing generator.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P5KhsOYILtKW"
      },
      "outputs": [],
      "source": [
        "#make sure to include scikit-image library into environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KbsN4bh5bJe",
        "outputId": "7065a163-3f21-427a-fb0c-9a6db8079d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#used during training on Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEWQNUi96PIJ",
        "outputId": "8082c09e-0419-4b8e-83d3-7adb341c5440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 471 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 522 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 552 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 604 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 634 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 686 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 716 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 747 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 768 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 798 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 829 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 849 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 880 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 931 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 942 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 962 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 993 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8rDHit-95irS"
      },
      "outputs": [],
      "source": [
        "#import modules and libraries for notebook\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "from cycleGAN_functions import *\n",
        "import math\n",
        "from scipy.linalg import sqrtm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vt9lQhfQkDP"
      },
      "source": [
        "<hr>\n",
        "\n",
        "#### FID Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIpaGx17wSD4"
      },
      "source": [
        "The first step is to define the Inception V3 model and functions for calculating activation from the model (embeddings) which is shown as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7dproER96WTe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f33218-f98c-46e6-9cca-7ebe53446364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "inception_model = tf.keras.applications.InceptionV3(include_top=False, \n",
        "                              weights=\"imagenet\", \n",
        "                              pooling='avg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GlCFPtnt6rXI"
      },
      "outputs": [],
      "source": [
        "def compute_embeddings(dataloader, count):\n",
        "    image_embeddings = []\n",
        "\n",
        "    for _ in range(count):\n",
        "        images = next(iter(dataloader))\n",
        "        embeddings = inception_model.predict(images)\n",
        "\n",
        "        image_embeddings.extend(embeddings)\n",
        "\n",
        "    return np.array(image_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "83vhhriTK8Fs"
      },
      "outputs": [],
      "source": [
        "def calculate_fid(embeddings1, embeddings2):\n",
        "    mu1 = embeddings1.mean(axis=0)\n",
        "    mu2 = embeddings2.mean(axis=0)\n",
        "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
        "\n",
        "    sigma1 = np.cov(embeddings1,  rowvar=False)\n",
        "    sigma2 = np.cov(embeddings2,  rowvar=False)\n",
        "    covmean = sqrtm(sigma1.dot(sigma2))\n",
        "\n",
        "    if np.iscomplexobj(covmean):\n",
        "      covmean = covmean.real\n",
        "\n",
        "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "    fid = round(fid)\n",
        "    return fid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1MJIIaKQsjB"
      },
      "source": [
        "<hr>\n",
        "\n",
        "#### SG12 Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtivK7HTwSD6"
      },
      "source": [
        "I will calculate the embeddings for each of the 3 trained generators by importing previously generated images in the previous notebook. These generated images are avaialable on the google drive or can be created via the trained models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfKUco9k8gCS",
        "outputId": "a376dd05-3649-4ac7-cef4-a035cceaba61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 751 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "#import images from generator trained to epoch 12\n",
        "gen_SG12 = tf.keras.utils.image_dataset_from_directory(\n",
        "        '/content/drive/MyDrive/cycleGAN_deliveryservice/generated_imgs/epoch12',\n",
        "        labels=None,\n",
        "        label_mode=None,\n",
        "        class_names=None,\n",
        "        color_mode='rgb',\n",
        "        batch_size=None,\n",
        "        image_size=(256,256),\n",
        "        shuffle=False,\n",
        "        seed=123,\n",
        "        validation_split=None,\n",
        "        subset=None,\n",
        "        interpolation='bilinear',\n",
        "        follow_links=True,\n",
        "        crop_to_aspect_ratio=False\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0qSEsaKY_Upc"
      },
      "outputs": [],
      "source": [
        "#Inception Model takes 299x299 images\n",
        "def resize299(image, size=[299,299]):\n",
        "    '''\n",
        "    Helper function to resize image to target value i.e. 299x299\n",
        "    '''\n",
        "    return tf.image.resize(image, size, preserve_aspect_ratio=True, method='bilinear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fpjv8fvD-hNt"
      },
      "outputs": [],
      "source": [
        "#apply resizing to each photo in dataset\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "gen_SG12 = gen_SG12.cache().map(\n",
        "    resize299, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GMo01UN570OG"
      },
      "outputs": [],
      "source": [
        "#calculate embeddings\n",
        "generated_image_embeddings12 = compute_embeddings(gen_SG12, count=751)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzvpYcMdCPxK",
        "outputId": "4a20f8bb-f736-4bcf-e094-6ded37863758"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(751, 2048)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#sanity check for shape\n",
        "generated_image_embeddings12.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_i6I8uDwSD8"
      },
      "source": [
        "I will perform a sanity check to ensure that when calculating the FID score for the same feature vectors against itself, it should be 0 since it would be exactly the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGv-IzYjPvgz",
        "outputId": "0b2bd646-cd70-4e72-d987-60a0d9611918"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#sanity check ---> the FID should be 0 since we are comparing the same feature vectors\n",
        "calculate_fid(generated_image_embeddings12,generated_image_embeddings12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U8HeHnqwSD8"
      },
      "source": [
        "In seeing that the FID score has calculated this properly, I will continue and perform the same for the generator trained to epoch 52 and 100 as well as calculate the embeddings for the real test SG images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpnyuo1jU85b"
      },
      "source": [
        "<hr>\n",
        "\n",
        "#### SG58 Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwROHe5RQCl1",
        "outputId": "ebec9c2d-8592-4546-a909-0402f49cc76d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 751 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "#import images from generator trained to epoch 58\n",
        "gen_SG58 = tf.keras.utils.image_dataset_from_directory(\n",
        "        '/content/drive/MyDrive/cycleGAN_deliveryservice/generated_imgs/epoch58',\n",
        "        labels=None,\n",
        "        label_mode=None,\n",
        "        class_names=None,\n",
        "        color_mode='rgb',\n",
        "        batch_size=None,\n",
        "        image_size=(256,256),\n",
        "        shuffle=False,\n",
        "        seed=None,\n",
        "        validation_split=None,\n",
        "        subset=None,\n",
        "        interpolation='bilinear',\n",
        "        follow_links=True,\n",
        "        crop_to_aspect_ratio=False\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tjeczmIIVJIi"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "gen_SG58 = gen_SG58.cache().map(\n",
        "    resize299, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "p1Mmh1BiVVbN"
      },
      "outputs": [],
      "source": [
        "generated_image_embeddings58 = compute_embeddings(gen_SG58, count=751)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCBrTzQsaQc1"
      },
      "source": [
        "<hr>\n",
        "\n",
        "#### SG100 Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVGiWCOIZ9D_",
        "outputId": "9960ad17-3985-48cb-c692-4da8737edc97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 751 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "gen_SG100 = tf.keras.utils.image_dataset_from_directory(\n",
        "        '/content/drive/MyDrive/cycleGAN_deliveryservice/generated_imgs/epoch100',\n",
        "        labels=None,\n",
        "        label_mode=None,\n",
        "        class_names=None,\n",
        "        color_mode='rgb',\n",
        "        batch_size=None,\n",
        "        image_size=(256,256),\n",
        "        shuffle=False,\n",
        "        seed=None,\n",
        "        validation_split=None,\n",
        "        subset=None,\n",
        "        interpolation='bilinear',\n",
        "        follow_links=True,\n",
        "        crop_to_aspect_ratio=False\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3ijZL23Bb8eH"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "gen_SG100 = gen_SG100.cache().map(\n",
        "    resize299, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZouGKtPqcH64"
      },
      "outputs": [],
      "source": [
        "generated_image_embeddings100 = compute_embeddings(gen_SG100, count=751)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beEybWrbga9V"
      },
      "source": [
        "<hr>\n",
        "\n",
        "#### Real SG Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbCc7sXofbKw",
        "outputId": "7e9f6dad-c9b1-43b8-9d19-10686c2d9c13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 380 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "real_SG = tf.keras.utils.image_dataset_from_directory(\n",
        "        '/content/drive/MyDrive/cycleGAN_deliveryservice/data/SG/testA',\n",
        "        labels=None,\n",
        "        label_mode=None,\n",
        "        class_names=None,\n",
        "        color_mode='rgb',\n",
        "        batch_size=None,\n",
        "        image_size=(1038, 1920),\n",
        "        shuffle=False,\n",
        "        seed=None,\n",
        "        validation_split=None,\n",
        "        subset=None,\n",
        "        interpolation='bilinear',\n",
        "        follow_links=True,\n",
        "        crop_to_aspect_ratio=False\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "L7eRlTcx7lmI"
      },
      "outputs": [],
      "source": [
        "def real_SG_preprocess(image):\n",
        "  image = normalize(image)\n",
        "  image = center_crop(image)\n",
        "  image = resize299(image)\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_rcC3Z5q1aO0"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "real_SG = real_SG.cache().map(\n",
        "    real_SG_preprocess, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hxuBHZwS7BeN"
      },
      "outputs": [],
      "source": [
        "real_image_embeddings = compute_embeddings(real_SG, count=380)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI4xXeZgDcgb"
      },
      "source": [
        "<hr>\n",
        "\n",
        "#### Calculating FID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Crp7lTwT7d5v"
      },
      "outputs": [],
      "source": [
        "FID12 = calculate_fid(generated_image_embeddings12, real_image_embeddings)\n",
        "FID58 = calculate_fid(generated_image_embeddings58, real_image_embeddings)\n",
        "FID100 = calculate_fid(generated_image_embeddings100, real_image_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lykMDqSGD9q5",
        "outputId": "8dce4e79-1992-48af-efb7-9a818e50cbf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID12 = 584583\n",
            "FID58 = 594082\n",
            "FID100 = 402783\n"
          ]
        }
      ],
      "source": [
        "print(\"FID12 =\", FID12)\n",
        "print(\"FID58 =\", FID58)\n",
        "print(\"FID100 =\", FID100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmyNZ-hGwSD_"
      },
      "source": [
        "From the FID Score calculated above, it can be seen that the generator that was trained for 100 epochs had the lowest score which means that it's feature vectors are closest to the feature vectors of the SG test images. \n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I046a7ovMhIe"
      },
      "source": [
        "#### Conclusion\n",
        "\n",
        "As demonstrated in this notebook, we have calculated the FID Score for generators trained to epoch 12, 58, and 100 with respective to Studio Ghibli feature vectors and found that my generator trained to epoch 100 produced the best score. There is still the issue with the non-convergence as seen in the previous notebook but for the problem space created, the results were satisfactory.\n",
        "\n",
        "Though not perfect, this concludes the notebooks and submission as the project is. For future iterations, I will look to employ different methods and architectures to increase generated image fidelity."
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "Dm2GAvzZKi3X",
        "8Vt9lQhfQkDP"
      ],
      "machine_shape": "hm",
      "name": "04 FID Score.ipynb",
      "provenance": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}